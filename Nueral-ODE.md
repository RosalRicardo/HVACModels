# Neural ODE

## Introduction

 + Neural networks are functions approximation
 + nn (input times weights add bias and activate)
 + neuralode for timeseries
 + better work than RNN for timeseries
 + neuralODE optimization with ode solvers
 + computing gradients with constant memory cost (linear complexity) 


## Residual Networks (ResNet)

 + feed the input of the previous layer and also of the antiprevious layer
 + x(k+1) = xk + F(xk) - formula for ResNet
 + add a constant to it, h for example ...
 + x(k+1) = xk + hF(xk)
 + this equation became the euler methods

 ![https://github.com/llSourcell/Neural_Differential_Equations/]

## ODE Networks
 + like a continous number of layers

## adjoint method
 + entender esse metodo!!
 + 
